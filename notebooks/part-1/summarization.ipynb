{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a776d521-d07d-44a0-a5b3-e5fba50f987c",
   "metadata": {},
   "source": [
    "## LLM Summarisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c0fc81-0e84-433f-b2f8-e7b9886bc1e1",
   "metadata": {},
   "source": [
    "LLMs are capable of condensing lengthy documents into concise summaries. They understand and extract the main ideas and key details from a text, presenting them in a clear and coherent manner. This is useful in areas like research, journalism, and daily information management, helping users to quickly grasp essential information from vast amounts of text.\n",
    "\n",
    "This guide will present several approachs to summarisation with LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd82d5d-7e43-4c45-830d-f222052f7a76",
   "metadata": {},
   "source": [
    "## Langchain Summarisation\n",
    "\n",
    "Langchain allows you to build more formal summarisation chains, using the following common approaches for loading documents into the LLM context window:\n",
    "\n",
    "- `Stuff` approach: The simplest approach which involves loading all your documents into the context window of the LLM (similar to the above raw direct summarisation).\n",
    "- `Map-Reduce` approach: This involves a chain with two steps - `map` and `reduce`. Essentially, the chain summarises each document separately during the `map` step and the `reduce`s these summaries into a final summary.\n",
    "\n",
    "The `Map-Reduce` approach is ideal for scenarios where the documents cannot fit into the LLM context window, so we split them into chunks, summarise those chunks (thereby reducing their size) and then summarise the list of summaries.\n",
    "\n",
    "<img src='https://python.langchain.com/assets/images/summarization_use_case_2-f2a4d5d60980a79140085fb7f8043217.png'/>\n",
    "\n",
    "### load_summarize_chain\n",
    "\n",
    "LangChain provides an optimised chain function called load_summarize_chain. This function abstracts the above two approaches (and uses them underneath). You provide the `chain_type` parameter to switch between `stuff` and `map_reduce`. You can optionally provide your own prompts as well, though it uses an internal prompt for summarisation by default.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd734c82-caba-412b-8ade-2e0cf1b4bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"mistral\", num_ctx=8196)  # Default is 2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff90c538-f5c0-4797-b940-d532782c3177",
   "metadata": {},
   "source": [
    "We can then create a stuff chain using the routines below, and finally invoke it to get our summary of the article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81e9f95f-f38a-4242-8314-024f6f066913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanup_newlines(docs):\n",
    "    for doc in docs:\n",
    "        doc.page_content = re.sub(\"\\n\\n+\", \"\\n\", doc.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aff0df6-125b-4a35-ab52-1b58d4bacd48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3885"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "docs = WebBaseLoader(\"https://medium.com/inspiredbrilliance/patterns-for-microservices-e57a2d71ff9e\").load()\n",
    "cleanup_newlines(docs)\n",
    "llm.get_num_tokens(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22098faf-a442-4de9-804e-c63482382950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The article \"Patterns for microservices - Sync vs Async\" by Priyank Gupta discusses the choice between synchronous and asynchronous communication styles in designing microservices architectures. The author notes that inter-service communication flow is a crucial decision that impacts various system dimensions, including consumers, workflow management, read/write frequency bias, and more.\\n\\nFor synchronous communication, components wait for a response before proceeding. It\\'s suitable for consumer applications that expect a unified interface and can mask the complexity of a distributed system. However, it lacks flexibility in handling complex workflows and doesn\\'t scale well for high read/write frequency systems.\\n\\nIn contrast, asynchronous communication allows components to decouple their execution by not waiting for a response. It\\'s an excellent fit for write-heavy systems and can handle sporadic bursts of traffic. However, it increases system complexity due to the need for message queues, event choreography, and orchestration.\\n\\nThe article also discusses various approaches within synchronous and asynchronous systems and their trade-offs, such as capacity balancing, cascading failures, load balancing & service discovery overhead, coupling, and more. The author suggests considering these factors when deciding on a communication style for microservices design.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "stuff_chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "stuff_chain.invoke(docs)[\"output_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0398315-2462-496e-833b-bd3e3fcaf5db",
   "metadata": {},
   "source": [
    "Next we begin by loading a larger piece of text, namely Franz Kafka's short story: Metamorphosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "516f049e-8212-4075-bf3c-6a76832cb0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "metamorphosis_url = \"https://www.gutenberg.org/cache/epub/5200/pg5200-images.html\"\n",
    "book_loader = WebBaseLoader(metamorphosis_url)\n",
    "book_docs = book_loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f5004a3-e067-4325-a4df-4f7f6fd24514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35727\n"
     ]
    }
   ],
   "source": [
    "print(llm.get_num_tokens(book_docs[0].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff94967d-8ba1-4023-8bd4-32dcc9c407a5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86e60cd3-18f1-4799-982e-96642e036253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=20000,\n",
    "    chunk_overlap=500\n",
    ")\n",
    "\n",
    "split_docs = splitter.split_documents(book_docs)\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa57f3ff-44a9-4b28-948a-23f12b16cde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' In \"Metamorphosis\" by Franz Kafka, the protagonist Gregor Samsa transforms into a giant insect-like creature and is unable to perform his duties as a traveling salesman. His family grows concerned about his absence from work and eventually confronts him, leading to misunderstandings and distress. Gregor tries to protect his family and find a solution but faces physical and emotional challenges. As days pass, the family\\'s financial situation worsens, and they struggle to care for Gregor while dealing with their own concerns. Eventually, due to their exhaustion and financial difficulties, they decide to lock Gregor in his room. One day, Gregor is found dead by the cleaner, leaving his family grieving. The story is part of Project Gutenberg, a digital library that distributes free electronic works with contributors providing royalties and donations.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_reduce_chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "map_reduce_chain.invoke(split_docs)[\"output_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1016c-9f0f-4ff0-9bb7-27ab6fc674c0",
   "metadata": {},
   "source": [
    "## Useful Links\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/use_cases/summarization/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
